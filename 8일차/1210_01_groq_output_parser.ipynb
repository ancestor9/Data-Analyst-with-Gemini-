{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ancestor9/Data-Analyst-with-Gemini-/blob/main/8%EC%9D%BC%EC%B0%A8/1210_01_groq_output_parser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **[Groq API](https://wikidocs.net/259655)**\n",
        "\n",
        "- https://console.groq.com/playground\n",
        "- https://python.langchain.com/docs/how_to/sequence/ **(Langchain Tutorial)**\n",
        "- https://wikidocs.net/book/14314 **(í•œê¸€íŒ ë‘ì²´ì¸ íŠœí† ë¦¬ì–¼)**"
      ],
      "metadata": {
        "id": "UmjMoIobUZr7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "groq_key = userdata.get('groq')"
      ],
      "metadata": {
        "id": "GuxZqRXkU-aA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LangChainê³¼ Groq APIë¥¼ ì—°ê²°í•˜ëŠ” íŒ¨í‚¤ì§€.\n",
        "# Groqì€ ì´ˆê³ ì† LLM ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ëŠ” AI íšŒì‚¬ì´ë©°, íŠ¹íˆ LLaMA, Mixtral, Gemma ë“±ì˜ ëª¨ë¸ì„ ë¹ ë¥´ê²Œ ì‹¤í–‰í•  ìˆ˜ ìˆìŒ.\n",
        "# ì´ íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©í•˜ë©´ LangChainì„ í†µí•´ Groqì˜ LLMì„ ì†ì‰½ê²Œ í™œìš©í•  ìˆ˜ ìˆìŒ.\n",
        "%%capture\n",
        "!pip install langchain-groq --quiet"
      ],
      "metadata": {
        "id": "V-dOigfFVNyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ptXYOaAUUAR"
      },
      "outputs": [],
      "source": [
        "from langchain_groq import ChatGroq\n",
        "\n",
        "# ChatGroq ëª¨ë¸ ì´ˆê¸°í™”\n",
        "llm = ChatGroq(\n",
        "    model=\"gemma2-9b-it\", # google/gemma-2-9b-it\n",
        "    temperature=0.7,\n",
        "    max_tokens=300,\n",
        "    api_key=groq_key\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYFHZ-QVMZJ1",
        "outputId": "e70a7004-0d0c-4091-dd72-b1173e273977"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x7d7af4d12d50>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x7d7af50a3f10>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'), max_tokens=300)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm.predict(\"ì•ˆë…•í•˜ì„¸ìš”?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "xzvPaWZnMRG6",
        "outputId": "5a9c24cd-6913-476e-e7df-293d17f3a8fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-e172f47a785f>:1: LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  llm.predict(\"ì•ˆë…•í•˜ì„¸ìš”?\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ì•ˆë…•í•˜ì„¸ìš”! ğŸ‘‹  ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? ğŸ˜Š\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ìœ ìµí•œ AI ì¡°ìˆ˜ì…ë‹ˆë‹¤. í•œêµ­ì˜ ì—­ì‚¬ì™€ ë¬¸í™”ì— ëŒ€í•´ ì˜ ì•Œê³  ìˆìŠµë‹ˆë‹¤.\"),\n",
        "    (\"human\", \"{question}\")\n",
        "])\n",
        "\n",
        "prompt"
      ],
      "metadata": {
        "id": "xyOjVepeVG2-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "535a8f0f-48f9-4023-8c25-a083abc7c393"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ìœ ìµí•œ AI ì¡°ìˆ˜ì…ë‹ˆë‹¤. í•œêµ­ì˜ ì—­ì‚¬ì™€ ë¬¸í™”ì— ëŒ€í•´ ì˜ ì•Œê³  ìˆìŠµë‹ˆë‹¤.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={})])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chain ìƒì„±\n",
        "chain = prompt | llm"
      ],
      "metadata": {
        "id": "qBrVIXdhVb3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸\n",
        "questions = [\n",
        "    \"í•œê¸€ì˜ ì°½ì œ ì›ë¦¬ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\",\n",
        "    \"ê¹€ì¹˜ì˜ ì—­ì‚¬ì™€ ë¬¸í™”ì  ì¤‘ìš”ì„±ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.\",\n",
        "    \"ì¡°ì„ ì‹œëŒ€ì˜ ê³¼ê±° ì œë„ì— ëŒ€í•´ ê°„ë‹¨íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.\"\n",
        "]\n",
        "\n",
        "# ê° ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„±\n",
        "for question in questions:\n",
        "    response = chain.invoke({\"question\": question})\n",
        "    print(f\"ì§ˆë¬¸: {question}\")\n",
        "    print(f\"ë‹µë³€: {response.content}\\n\") # Use response.content to access the text\n",
        "    print(\"*\" * 150)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZyLdPjwVxb0",
        "outputId": "7490a927-e4d8-466a-a0a0-32bf40f23495"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì§ˆë¬¸: í•œê¸€ì˜ ì°½ì œ ì›ë¦¬ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\n",
            "ë‹µë³€: í•œê¸€ì˜ ì°½ì œ ì›ë¦¬ëŠ” **ìì—°ì˜ ì†Œë¦¬ë¥¼ ë”°ë¼ ê¸€ìë¥¼ ë§Œë“¤ì–´ë‚´ëŠ” ê²ƒ**ì— ìˆìŠµë‹ˆë‹¤. \n",
            "\n",
            "ì„¸ì¢…ëŒ€ì™•ì´ ë°±ì„±ë“¤ì´ ì‰½ê²Œ ë°°ìš°ê³  ì“°ê¸° ì‰½ë„ë¡ ë§Œë“¤ê³ ì í–ˆë˜ ê²ƒì…ë‹ˆë‹¤.  \n",
            "\n",
            "ì¢€ ë” ìì„¸íˆ ì„¤ëª…ë“œë¦¬ìë©´:\n",
            "\n",
            "* **ììŒ**: ììŒì€ ì…ìˆ , í˜€, ê¸°ì¹¨, ì°Œë¥´ëŠ” í˜ ë“± **ìŒì„±ì„ ë‚´ëŠ” ê¸°ê´€ì˜ ì›€ì§ì„**ì„ ë³¸ë–  ë§Œë“¤ì–´ì¡ŒìŠµë‹ˆë‹¤. \n",
            "* **ëª¨ìŒ**: ëª¨ìŒì€ **ìŒì„±ì„ ë‚¼ ë•Œ ì…ìˆ ê³¼ í˜€ê°€ ë§Œë“œëŠ” ëª¨ì–‘**ì„ ë³¸ë–  ë§Œë“¤ì–´ì¡ŒìŠµë‹ˆë‹¤.\n",
            "\n",
            "ì´ëŸ¬í•œ ìì—°ì˜ ì›ë¦¬ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œê¸€ì€ ë§¤ìš° ì²´ê³„ì ì´ê³  ë…¼ë¦¬ì ì¸ ê¸€ì ì²´ê³„ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.  í•œê¸€ì˜ ì°½ì œ ì›ë¦¬ëŠ” ë‹¨ìˆœí•˜ì§€ë§Œ ë§¤ìš° í˜ì‹ ì ì´ì—ˆìœ¼ë©°, ì„¸ê³„ì ìœ¼ë¡œë„ ì¹­ì°¬ë°›ëŠ” ì‚¬ë¡€ì…ë‹ˆë‹¤. \n",
            "\n",
            "\n",
            "ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë¬¼ì–´ë³´ì„¸ìš”! ğŸ˜Š\n",
            "\n",
            "\n",
            "******************************************************************************************************************************************************\n",
            "ì§ˆë¬¸: ê¹€ì¹˜ì˜ ì—­ì‚¬ì™€ ë¬¸í™”ì  ì¤‘ìš”ì„±ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n",
            "ë‹µë³€: ## ê¹€ì¹˜: í•œêµ­ì˜ ë§›ê³¼ ë¬¸í™”ë¥¼ ë‹´ì€ ì „í†µ ìŒì‹\n",
            "\n",
            "ê¹€ì¹˜ëŠ” ë‹¨ìˆœí•œ ìŒì‹ì„ ë„˜ì–´ í•œêµ­ì¸ì˜ ì‚¶ê³¼ ë¬¸í™”ë¥¼ ëŒ€ë³€í•˜ëŠ” ì¤‘ìš”í•œ ìš”ì†Œì…ë‹ˆë‹¤. \n",
            "\n",
            "**ì—­ì‚¬**:\n",
            "\n",
            "* **ê¸°ì›:** ê¹€ì¹˜ì˜ ì—­ì‚¬ëŠ” ì •í™•íˆ ì–¸ê¸‰ë˜ì§€ëŠ” ì•Šì•˜ì§€ë§Œ, ê¸°ì›ì „ 300ë…„ê²½ë¶€í„° ë°œë‹¬ë˜ì—ˆë‹¤ëŠ” ì¶”ì¸¡ì´ ìˆìŠµë‹ˆë‹¤. ì´ˆê¸°ì—ëŠ” ì—¼ì¥, ë°œíš¨ ë“±ì„ ì´ìš©í•˜ì—¬ ìŒì‹ì„ ë³´ê´€í•˜ëŠ” ë°©ì‹ì´ì—ˆê³ , ê³§ ë§›ì˜ ë³€í™”ì™€ ì˜ì–‘ì  ê°€ì¹˜ë¥¼ ë†’ì´ëŠ” ê³¼ì •ìœ¼ë¡œ ë°œì „í–ˆìŠµë‹ˆë‹¤.\n",
            "* **ê³ ë ¤ ì‹œëŒ€:** ê¹€ì¹˜ê°€ ë³´ë‹¤ ë‹¤ì–‘í•˜ê²Œ ë§Œë“¤ì–´ì§€ê¸° ì‹œì‘í–ˆìœ¼ë©°,  \"ê¹€ì¹˜\"ë¼ëŠ” ëª…ì¹­ì´ ì²˜ìŒ ë“±ì¥í•©ë‹ˆë‹¤. \n",
            "* **ì¡°ì„  ì‹œëŒ€:** ê¹€ì¹˜ëŠ” ê¶ì¤‘ ìŒì‹ë¶€í„° ë°±ì„±ë“¤ì˜ ì‹íƒê¹Œì§€ ë„ë¦¬ ì„­ì·¨ë˜ê¸° ì‹œì‘í–ˆìŠµë‹ˆë‹¤. ë‹¤ì–‘í•œ ì¬ë£Œì™€ ë ˆì‹œí”¼ê°€ ê°œë°œë˜ë©´ì„œ í•œêµ­ì˜ ì§€ì—­ íŠ¹ì„±ì„ ë°˜ì˜í•˜ëŠ” ê¹€ì¹˜ ë¬¸í™”ê°€ í˜•ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
            "\n",
            "**ë¬¸í™”ì  ì¤‘ìš”ì„±**:\n",
            "\n",
            "* **ìŒì‹ ë¬¸í™”:** ê¹€ì¹˜ëŠ” í•œêµ­ì¸ì˜ ì‹íƒì—ì„œ ë¹ ì§ˆ ìˆ˜ ì—†ëŠ” í•„ìˆ˜ì ì¸ ìŒì‹ì…ë‹ˆë‹¤. ë°¥ê³¼ í•¨ê»˜ ê³ë“¤ì´ê±°ë‚˜, êµ­ì´ë‚˜ì°Œê°œì˜ ì¬ë£Œë¡œ ì‚¬ìš©ë˜ëŠ” ë“±\n",
            "\n",
            "******************************************************************************************************************************************************\n",
            "ì§ˆë¬¸: ì¡°ì„ ì‹œëŒ€ì˜ ê³¼ê±° ì œë„ì— ëŒ€í•´ ê°„ë‹¨íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n",
            "ë‹µë³€: ì¡°ì„ ì‹œëŒ€ì˜ ê³¼ê±° ì œë„ëŠ” ì‚¬ë¦¼ì„ ì¤‘ì‹œí•˜ëŠ” ê³¼ê±°ì‹œí—˜ì„ í†µí•´ ê´€ë¦¬ìë¥¼ ì„ ë°œí•˜ëŠ” ì œë„ì˜€ìŠµë‹ˆë‹¤. \n",
            "\n",
            "**í•µì‹¬ íŠ¹ì§•ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:**\n",
            "\n",
            "* **ì„ê¸ˆ ì§ì ‘ ê´€ë¦¬:** ê³¼ê±°ëŠ” ì™•ì´ ì§ì ‘ ì£¼ê´€í•˜ê³ , ì™•ê¶Œì˜ í•œ í‘œí˜„ìœ¼ë¡œ ì—¬ê²¨ì¡ŒìŠµë‹ˆë‹¤.\n",
            "* **ê³ ë“± ê´€ë¦¬ ì–‘ì„±:** ê³¼ê±°ë¥¼ í†µí•´ ê¸‰ì—¬ì™€ ë†’ì€ ì‚¬íšŒ ì§€ìœ„ë¥¼ ë°›ëŠ” ê³ ë“± ê´€ë¦¬ê°€ ì„ ë°œë˜ì—ˆìŠµë‹ˆë‹¤. \n",
            "* **ëŠ¥ë ¥ ì¤‘ì‹¬ í‰ê°€:** ì „ë¬¸ì ì¸ ì§€ì‹ê³¼ ì •ì¹˜ì  ëŠ¥ë ¥ì„ í‰ê°€í•˜ëŠ” ì‹œí—˜ìœ¼ë¡œ, ë¬¸ì¥ ëŠ¥ë ¥ê³¼ ì—­ì‚¬, ì² í•™ ë“±ì„ ë¬»ëŠ” ì‹œí—˜ì´ì—ˆìŠµë‹ˆë‹¤.\n",
            "\n",
            "**ê³¼ê±° ì‹œí—˜ì˜ ê³¼ì •ì€ í¬ê²Œ ì„¸ ë‹¨ê³„ë¡œ ë‚˜ë‰˜ì—ˆìŠµë‹ˆë‹¤:**\n",
            "\n",
            "1. **ì‹œí—˜ ì¤€ë¹„:** 3~4ë…„ ë™ì•ˆ ê¹Šì´ ìˆëŠ” í•™ë¬¸ì„ ìµí˜€ì•¼ í–ˆìŠµë‹ˆë‹¤.\n",
            "2. **ì‹œí—˜ ì‘ì‹œ:** ì„±ê²©, ì§€ë¦¬, ì‹œ, ëª½, ì •, ì†Œì„¤, ì—­ì‚¬, ë²• ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì˜ ì‹œí—˜ì„ ì¹˜ë €ìŠµë‹ˆë‹¤.\n",
            "3. **ë“±ë¡ ë° ì„ìš©:** í•©ê²©ìëŠ” ë“±ê¸‰ì„ ë°›ê³ , ê·¸ì— ë”°ë¼ ê´€ë£Œë¡œ ì„ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
            "\n",
            "**ì¡°ì„ ì˜ ê³¼ê±° ì œë„ëŠ”** íƒì›”\n",
            "\n",
            "******************************************************************************************************************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **UI ë§Œë“¤ê¸°**"
      ],
      "metadata": {
        "id": "BUKYHfvQJppT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: gradioë¡œ ë§Œë“¤ì–´ì¤˜\n",
        "%%capture\n",
        "!pip install gradio --quiet"
      ],
      "metadata": {
        "id": "IGtlTlFVVr17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **gradio**"
      ],
      "metadata": {
        "id": "5HmYnOjdNAh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "import gradio as gr\n",
        "\n",
        "groq_key = userdata.get('groq')\n",
        "\n",
        "# ChatGroq ëª¨ë¸ ì´ˆê¸°í™”\n",
        "llm = ChatGroq(\n",
        "    model=\"gemma2-9b-it\",\n",
        "    temperature=0.7,\n",
        "    max_tokens=300,\n",
        "    api_key=groq_key\n",
        ")\n",
        "\n",
        "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ìœ ìµí•œ AI ì¡°ìˆ˜ì…ë‹ˆë‹¤. í•œêµ­ì˜ ì—­ì‚¬ì™€ ë¬¸í™”ì— ëŒ€í•´ ì˜ ì•Œê³  ìˆìŠµë‹ˆë‹¤.\"),\n",
        "    (\"human\", \"{question}\")\n",
        "])\n",
        "\n",
        "# Chain ìƒì„±\n",
        "chain = prompt | llm\n",
        "\n",
        "def predict(message):\n",
        "    response = chain.invoke({\"question\": message})\n",
        "    return response.content\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=predict,\n",
        "    inputs=gr.Textbox(lines=2, placeholder=\"Enter your question here...\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"Korean History & Culture Q&A\",\n",
        "    description=\"Ask me anything about Korean history and culture!\",\n",
        ")\n",
        "\n",
        "iface.launch()"
      ],
      "metadata": {
        "id": "8Ty2K_MgdmBp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "outputId": "4ecf1d8d-1096-4479-9225-ef8ee275da6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://a2bff48681be50660a.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a2bff48681be50660a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "# template ì •ì˜. {country}ëŠ” ë³€ìˆ˜ë¡œ, ì´í›„ì— ê°’ì´ ë“¤ì–´ê°ˆ ìë¦¬ë¥¼ ì˜ë¯¸\n",
        "template = \"{country}ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?\"\n",
        "\n",
        "# from_template ë©”ì†Œë“œë¥¼ ì´ìš©í•˜ì—¬ PromptTemplate ê°ì²´ ìƒì„±\n",
        "prompt_template = PromptTemplate.from_template(template) # Change prompt to prompt_template\n",
        "\n",
        "# prompt ìƒì„±. format ë©”ì†Œë“œë¥¼ ì´ìš©í•˜ì—¬ ë³€ìˆ˜ì— ê°’ì„ ë„£ì–´ì¤Œ\n",
        "prompt_string = prompt_template.format(country=\"ëŒ€í•œë¯¼êµ­\") # Create a new variable to hold the formatted string\n",
        "\n",
        "\n",
        "# chain ìƒì„±\n",
        "chain = prompt_template | llm  # Use the original prompt_template object in the chain"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "FCPTlFtKcUBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6NUhLEhcFvp",
        "outputId": "df67a5cf-a02e-4bbd-969b-2cd7ba61db9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['country'], input_types={}, partial_variables={}, template='{country}ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?')\n",
              "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x7985d3d710d0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x7985d45ae090>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'), max_tokens=300)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# country ë³€ìˆ˜ì— ì…ë ¥ëœ ê°’ì´ ìë™ìœ¼ë¡œ ì¹˜í™˜ë˜ì–´ ìˆ˜í–‰ë¨\n",
        "chain.invoke(\"ëŒ€í•œë¯¼êµ­\").content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9X7nIMuochHy",
        "outputId": "34da63e2-e6e1-4d92-825d-c4f439520dcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” **ì„œìš¸**ì…ë‹ˆë‹¤. ğŸ˜Š  \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke(\"í”„ë‘ìŠ¤\").content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "smJIyqEKNQTi",
        "outputId": "c936bd55-ea47-4f6a-e156-b5f4da4eb3a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'í”„ë‘ìŠ¤ì˜ ìˆ˜ë„ëŠ” **íŒŒë¦¬**ì…ë‹ˆë‹¤. ğŸ‡«ğŸ‡·  \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ì¶œë ¥íŒŒì„œ(Output Parser)**\n",
        "### **LangChainì˜ ì¶œë ¥íŒŒì„œëŠ” ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì¶œë ¥ì„ ë” ìœ ìš©í•˜ê³  êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ë³€í™˜í•˜ëŠ” ì¤‘ìš”í•œ ì»´í¬ë„ŒíŠ¸**"
      ],
      "metadata": {
        "id": "GhSFT1D_gG6H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Fewshot Prompt**"
      ],
      "metadata": {
        "id": "A-bKDWWfdgx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "import gradio as gr\n",
        "\n",
        "# Retrieve Groq API key\n",
        "groq_key = userdata.get('groq')\n",
        "\n",
        "# Initialize ChatGroq model\n",
        "llm = ChatGroq(\n",
        "    model=\"gemma2-9b-it\",\n",
        "    temperature=0.7,\n",
        "    max_tokens=300,\n",
        "    api_key=groq_key\n",
        ")\n",
        "\n",
        "# Few-Shot Prompting Template for Korean Historical Figures\n",
        "few_shot_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"You are an expert in providing concise, informative descriptions of Korean historical figures.\n",
        "    Always provide a response in the following format:\n",
        "    - Name: [Full Name]\n",
        "    - Era: [Historical Period]\n",
        "    - Key Achievements: [3-4 most significant contributions]\n",
        "    - Impact: [Lasting influence on Korean history]\"\"\"),\n",
        "\n",
        "    # Few-shot examples to guide the model's response\n",
        "    (\"human\", \"Tell me about King Sejong\"),\n",
        "    (\"ai\", \"\"\"- Name: ì„¸ì¢…ëŒ€ì™• (King Sejong the Great)\n",
        "            - Era: Joseon Dynasty (1418-1450)\n",
        "            - Key Achievements:\n",
        "            1. Created Hangul (Korean alphabet)\n",
        "            2. Advanced scientific and cultural development\n",
        "            3. Expanded agricultural techniques\n",
        "            4. Promoted education and scholarship\n",
        "            - Impact: Considered one of the most important monarchs in Korean history, revolutionized communication and cultural understanding\"\"\"),\n",
        "\n",
        "    (\"human\", \"Tell me about Admiral Yi Sun-sin\"),\n",
        "    (\"ai\", \"\"\"- Name: ì´ìˆœì‹  (Admiral Yi Sun-sin)\n",
        "            - Era: Joseon Dynasty (Late 16th century)\n",
        "            - Key Achievements:\n",
        "            1. Defended Korea against Japanese invasions\n",
        "            2. Invented the Turtle Ship (Geobukseon)\n",
        "            3. Won 23 consecutive naval battles\n",
        "            4. Exemplified military strategy and leadership\n",
        "            - Impact: National hero who prevented Japanese conquest and saved Korea during the Imjin War\"\"\"),\n",
        "\n",
        "    # The actual query will be added dynamically\n",
        "    (\"human\", \"{historical_figure}\")\n",
        "])\n",
        "\n",
        "# Create the chain\n",
        "chain = few_shot_prompt | llm\n",
        "\n",
        "# Gradio interface function\n",
        "def predict(historical_figure):\n",
        "    response = chain.invoke({\"historical_figure\": historical_figure})\n",
        "    return response.content\n",
        "\n",
        "predict('ê²½ë³µê¶')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "EVykw5VBdg5R",
        "outputId": "a6b398e1-da4d-4225-b78b-7704806b8ae7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'- Name: ê²½ë³µê¶ (Gyeongbokgung)\\n- Era: Joseon Dynasty (Built in 1395)\\n- Key Achievements:\\n    1.  Largest and most magnificent royal palace in Seoul\\n    2. Served as the main residence of Joseon Dynasty kings\\n    3.  Home to numerous architectural marvels and cultural treasures\\n    4.  Symbol of Korean history and traditional aesthetics\\n- Impact:  Iconic landmark and UNESCO World Heritage site, representing the grandeur and cultural heritage of Korea.  A popular tourist destination and important site for historical and cultural study. \\n\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=predict,\n",
        "    inputs=gr.Textbox(lines=1, placeholder=\"Enter a Korean historical figure's name...\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"Korean Historical Figures Insights\",\n",
        "    description=\"Get structured information about significant people in Korean history\"\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "iface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "MLY3_MFYOCM2",
        "outputId": "e80de182-8ebb-4ca1-c0d3-ee6cdfb536ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://c5d08cdafdedafcec1.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://c5d08cdafdedafcec1.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. PydanticOuputParser**\n",
        "- **PydanticOutputParser ëŠ” ì–¸ì–´ ëª¨ë¸ì˜ ì¶œë ¥ì„ ë” êµ¬ì¡°í™”ëœ ì •ë³´ë¡œ ë³€í™˜ í•˜ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” í´ë˜ìŠ¤**\n",
        "- **ë‹¨ìˆœ í…ìŠ¤íŠ¸ í˜•íƒœì˜ ì‘ë‹µ ëŒ€ì‹ , ì‚¬ìš©ìê°€ í•„ìš”ë¡œ í•˜ëŠ” ì •ë³´ë¥¼ ëª…í™•í•˜ê³  ì²´ê³„ì ì¸ í˜•íƒœë¡œ ì œê³µ**"
      ],
      "metadata": {
        "id": "swVoOFbpdh4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import PydanticOutputParser\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain_groq import ChatGroq\n",
        "from google.colab import userdata\n",
        "import gradio as gr\n",
        "\n",
        "# Retrieve Groq API key\n",
        "groq_key = userdata.get('groq')\n",
        "\n",
        "# Define a Pydantic model for structured historical figure information\n",
        "class HistoricalFigure(BaseModel):\n",
        "    name: str = Field(description=\"Full name of the historical figure\")\n",
        "    korean_name: str = Field(description=\"Name in Korean characters\")\n",
        "    birth_year: int = Field(description=\"Year of birth\")\n",
        "    death_year: int = Field(description=\"Year of death\")\n",
        "    era: str = Field(description=\"Historical period\")\n",
        "    key_achievements: List[str] = Field(description=\"3-4 most significant contributions\")\n",
        "    impact: str = Field(description=\"Lasting influence on Korean history\")\n",
        "    interesting_fact: str = Field(description=\"A unique or surprising detail about the figure\")\n",
        "\n",
        "# Initialize ChatGroq model\n",
        "llm = ChatGroq(\n",
        "    model=\"gemma2-9b-it\",\n",
        "    temperature=0.7,\n",
        "    max_tokens=500,\n",
        "    api_key=groq_key\n",
        ")\n",
        "\n",
        "# Create a PydanticOutputParser\n",
        "parser = PydanticOutputParser(pydantic_object=HistoricalFigure)\n",
        "\n",
        "# Create a prompt template that includes output instructions\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"You are an expert historian specializing in Korean history.\n",
        "    Provide detailed, accurate information about historical figures.\n",
        "\n",
        "    Only respond with information about **Korean historical people**, not places or buildings.\n",
        "\n",
        "    {format_instructions}\n",
        "\n",
        "    Please provide comprehensive information about the requested historical figure.\"\"\"),\n",
        "    (\"human\", \"{historical_figure}\")\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "# Combine the prompt, parsing instructions, and model\n",
        "chain = prompt.partial(format_instructions=parser.get_format_instructions()) | llm | parser\n",
        "\n",
        "# Gradio interface function\n",
        "def get_historical_figure_info(figure_name):\n",
        "    try:\n",
        "        result = chain.invoke({\"historical_figure\": figure_name})\n",
        "        # Convert Pydantic model to a formatted string\n",
        "        return \"\\n\".join([\n",
        "            f\"**Name:** {result.name} ({result.korean_name})\",\n",
        "            f\"**Lived:** {result.birth_year} - {result.death_year}\",\n",
        "            f\"**Era:** {result.era}\",\n",
        "            \"**Key Achievements:**\",\n",
        "            *[f\"- {achievement}\" for achievement in result.key_achievements],\n",
        "            f\"\\n**Historical Impact:** {result.impact}\",\n",
        "            f\"\\n**Interesting Fact:** {result.interesting_fact}\"\n",
        "        ])\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {str(e)}\"\n",
        "\n",
        "# Create Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=get_historical_figure_info,\n",
        "    inputs=gr.Textbox(lines=1, placeholder=\"Enter a Korean historical figure's name...\"),\n",
        "    outputs=\"markdown\",\n",
        "    title=\"Structured Korean Historical Figures\",\n",
        "    description=\"Get detailed, structured information about significant people in Korean history\"\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "iface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "XY7_WtRTer4J",
        "outputId": "ca3314c9-6cd9-49de-a928-c61a3a011dde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://1ff05f3fe5f8e84ed4.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://1ff05f3fe5f8e84ed4.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. JsonOutputParser**\n",
        "- **ì¶œë ¥ íŒŒì„œëŠ” ì‚¬ìš©ìê°€ ì›í•˜ëŠ” JSON ìŠ¤í‚¤ë§ˆë¥¼ ì§€ì •í•  ìˆ˜ ìˆê²Œ í•´ì£¼ë©°, ê·¸ ìŠ¤í‚¤ë§ˆì— ë§ê²Œ LLMì—ì„œ ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ì—¬ ê²°ê³¼ë¥¼ ë„ì¶œ**\n",
        "- **LLMì´ ë°ì´í„°ë¥¼ ì •í™•í•˜ê³  íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ì—¬ ì›í•˜ëŠ” í˜•íƒœì˜ JSONì„ ìƒì„±í•˜ê¸° ìœ„í•´ì„œëŠ”, ëª¨ë¸ì˜ ìš©ëŸ‰(ì—¬ê¸°ì„œëŠ” ì¸í…”ë¦¬ì „ìŠ¤ë¥¼ ì˜ë¯¸**\n",
        "- **ì˜ˆ. llama-70B ì´ llama-8B ë³´ë‹¤ ìš©ëŸ‰ì´ í¬ë‹¤) ì´ ì¶©ë¶„í•´ì•¼ í•œë‹¤ëŠ” ì ì„ ì°¸ê³ **"
      ],
      "metadata": {
        "id": "pQ4ILdl8euii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain_groq import ChatGroq\n",
        "from google.colab import userdata\n",
        "import gradio as gr\n",
        "import json\n",
        "\n",
        "# Retrieve Groq API key\n",
        "groq_key = userdata.get('groq')\n",
        "\n",
        "# Initialize ChatGroq model\n",
        "llm = ChatGroq(\n",
        "    model=\"gemma2-9b-it\",\n",
        "    temperature=0.7,\n",
        "    max_tokens=500,\n",
        "    api_key=groq_key\n",
        ")\n",
        "\n",
        "# Create a JsonOutputParser\n",
        "parser = JsonOutputParser()\n",
        "\n",
        "# Create a prompt template that includes JSON output instructions\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"You are an expert historian specializing in Korean history.\n",
        "    Provide detailed, accurate information about historical figures in a strict JSON format.\n",
        "\n",
        "    Respond with a JSON object containing the following keys:\n",
        "    - name: Full name of the historical figure\n",
        "    - korean_name: Name in Korean characters\n",
        "    - birth_year: Year of birth (integer)\n",
        "    - death_year: Year of death (integer)\n",
        "    - era: Historical period\n",
        "    - key_achievements: List of most significant contributions\n",
        "    - impact: Lasting influence on Korean history\n",
        "    - interesting_fact: A unique or surprising detail about the figure\n",
        "\n",
        "    {format_instructions}\"\"\"),\n",
        "    (\"human\", \"Tell me about {historical_figure}\")\n",
        "])\n",
        "\n",
        "# Combine the prompt, parsing instructions, and model\n",
        "chain = prompt.partial(format_instructions=parser.get_format_instructions()) | llm | parser\n",
        "\n",
        "# Gradio interface function\n",
        "def get_historical_figure_info(figure_name):\n",
        "    try:\n",
        "        result = chain.invoke({\"historical_figure\": figure_name})\n",
        "\n",
        "        # Format the JSON result as a readable markdown string\n",
        "        formatted_output = \"\\n\".join([\n",
        "            f\"**Name:** {result.get('name', 'N/A')} ({result.get('korean_name', 'N/A')})\",\n",
        "            f\"**Lived:** {result.get('birth_year', 'N/A')} - {result.get('death_year', 'N/A')}\",\n",
        "            f\"**Era:** {result.get('era', 'N/A')}\",\n",
        "            \"**Key Achievements:**\",\n",
        "            *[f\"- {achievement}\" for achievement in result.get('key_achievements', [])],\n",
        "            f\"\\n**Historical Impact:** {result.get('impact', 'N/A')}\",\n",
        "            f\"\\n**Interesting Fact:** {result.get('interesting_fact', 'N/A')}\"\n",
        "        ])\n",
        "\n",
        "        # Also return the raw JSON for reference\n",
        "        return formatted_output + f\"\\n\\n**Raw JSON:**\\n```json\\n{json.dumps(result, indent=2, ensure_ascii=False)}```\"\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {str(e)}\"\n",
        "\n",
        "# Create Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=get_historical_figure_info,\n",
        "    inputs=gr.Textbox(lines=1, placeholder=\"Enter a Korean historical figure's name...\"),\n",
        "    outputs=\"markdown\",\n",
        "    title=\"Structured Korean Historical Figures (JSON)\",\n",
        "    description=\"Get detailed, structured JSON information about significant people in Korean history\"\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "iface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "lqCGFhvZgEY_",
        "outputId": "b4a235c4-76b0-4f44-9cc2-273179be41c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://7d150e5c9acfc512cf.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://7d150e5c9acfc512cf.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. PandasDataFrameOutputParser**\n",
        "- **Pandas DataFrameì€ Python í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì—ì„œ ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” ë°ì´í„° êµ¬ì¡°ë¡œ, ë°ì´í„° ì¡°ì‘ ë° ë¶„ì„ì„ ìœ„í•´ í”íˆ ì‚¬ìš©ë˜ë©° êµ¬ì¡°í™”ëœ ë°ì´í„°ë¥¼ ë‹¤ë£¨ê¸° ìœ„í•œ í¬ê´„ì ì¸ ë„êµ¬ ì„¸íŠ¸ë¥¼ ì œê³µí•˜ì—¬, ë°ì´í„° ì •ì œ, ë³€í™˜ ë° ë¶„ì„ê³¼ ê°™ì€ ì‘ì—…ì— ë‹¤ì–‘í•˜ê²Œ í™œìš©**"
      ],
      "metadata": {
        "id": "2-0T-uYug6Qm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import gradio as gr\n",
        "\n",
        "# ì˜ˆì‹œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° í”„ë ˆì„ ìƒì„± í•¨ìˆ˜ ì •ì˜\n",
        "def get_historical_figures(figure_name=None):\n",
        "    # í•œêµ­ ì—­ì‚¬ì  ì¸ë¬¼ë“¤ì— ëŒ€í•œ ì˜ˆì‹œ ë°ì´í„°\n",
        "    figures_list = [\n",
        "        {\n",
        "            \"name\": \"Yi Sun-sin\",\n",
        "            \"korean_name\": \"ì´ìˆœì‹ \",\n",
        "            \"birth_year\": 1545,\n",
        "            \"death_year\": 1598,\n",
        "            \"era\": \"Joseon Dynasty\",\n",
        "            \"primary_role\": \"Admiral\",\n",
        "            \"key_achievement\": \"Defeated Japanese Navy during the Imjin War\",\n",
        "            \"historical_significance\": \"National hero known for his naval victories against Japan\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Sejong the Great\",\n",
        "            \"korean_name\": \"ì„¸ì¢…ëŒ€ì™•\",\n",
        "            \"birth_year\": 1397,\n",
        "            \"death_year\": 1450,\n",
        "            \"era\": \"Joseon Dynasty\",\n",
        "            \"primary_role\": \"King of Joseon\",\n",
        "            \"key_achievement\": \"Created the Korean alphabet Hangul\",\n",
        "            \"historical_significance\": \"One of the most respected kings, greatly improved Korean culture and literacy\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Kim Gu\",\n",
        "            \"korean_name\": \"ê¹€êµ¬\",\n",
        "            \"birth_year\": 1876,\n",
        "            \"death_year\": 1949,\n",
        "            \"era\": \"Korean Empire / Japanese Occupation\",\n",
        "            \"primary_role\": \"Politician\",\n",
        "            \"key_achievement\": \"Leader of the Korean independence movement\",\n",
        "            \"historical_significance\": \"Major figure in the movement for Korean independence from Japan\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # ë°ì´í„°ë¥¼ pandas DataFrameìœ¼ë¡œ ë³€í™˜\n",
        "    df = pd.DataFrame(figures_list)\n",
        "\n",
        "    # íŠ¹ì • ì¸ë¬¼ ì´ë¦„ì„ ì…ë ¥ë°›ì•˜ì„ ê²½ìš° í•„í„°ë§\n",
        "    if figure_name:\n",
        "        df = df[(df['korean_name'] == figure_name) | (df['name'] == figure_name)]\n",
        "\n",
        "    # ë°ì´í„°ê°€ ì—†ì„ ê²½ìš° ë©”ì‹œì§€ë¥¼ ë‹´ì€ DataFrame ë°˜í™˜\n",
        "    if df.empty:\n",
        "        return pd.DataFrame([{\"Message\": f\"No information found for {figure_name}\"}])\n",
        "\n",
        "    return df\n",
        "\n",
        "# Gradio ì¸í„°í˜ì´ìŠ¤ ì •ì˜\n",
        "iface = gr.Interface(\n",
        "    fn=get_historical_figures,\n",
        "    inputs=\"text\",  # íŠ¹ì • ì—­ì‚¬ì  ì¸ë¬¼ ì´ë¦„ì„ ì…ë ¥ë°›ê¸° ìœ„í•´ í…ìŠ¤íŠ¸ ì…ë ¥ ì‚¬ìš©\n",
        "    outputs=\"dataframe\",  # ë°ì´í„° í”„ë ˆì„ì„ ì¶œë ¥\n",
        "    title=\"Structured Korean Historical Figures (Pandas DataFrame)\",\n",
        "    description=\"Get detailed, structured information about significant people in Korean history\"\n",
        ")\n",
        "\n",
        "# ì¸í„°í˜ì´ìŠ¤ ì‹¤í–‰\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "VnXGlfYvg_3x",
        "outputId": "d7dc6517-3360-4a50-fe9c-83c6f8e9d802"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://077dc05f4c18c5aa97.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://077dc05f4c18c5aa97.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain_core.output_parsers as parsers\n",
        "print(dir(parsers))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yc1hYTW3hSsR",
        "outputId": "7a859ceb-4cc5-4f30-8b65-b5ce8b3c6440"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['BaseCumulativeTransformOutputParser', 'BaseGenerationOutputParser', 'BaseLLMOutputParser', 'BaseOutputParser', 'BaseTransformOutputParser', 'CommaSeparatedListOutputParser', 'JsonOutputKeyToolsParser', 'JsonOutputParser', 'JsonOutputToolsParser', 'ListOutputParser', 'MarkdownListOutputParser', 'NumberedListOutputParser', 'PydanticOutputParser', 'PydanticToolsParser', 'SimpleJsonOutputParser', 'StrOutputParser', 'XMLOutputParser', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'base', 'format_instructions', 'json', 'list', 'openai_tools', 'pydantic', 'string', 'transform', 'xml']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rnUM5Gt4kKV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain.chat_models import init_chat_model\n",
        "\n",
        "# # Now you can initialize the model with the retrieved API key\n",
        "# model = init_chat_model(\"llama3-8b-8192\", model_provider=\"groq\", api_key=groq_key)"
      ],
      "metadata": {
        "id": "K0dVkaBjiYz6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}